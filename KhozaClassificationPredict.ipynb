{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Classification Predict\n",
    "\n",
    "Â© Explore Data Science Academy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Honour Code\n",
    "\n",
    "I **SIBUSISO KHOZA**, confirm - by submitting this document - that the solutions in this notebook are a result of my own work and that I abide by the EDSA honour code (https://drive.google.com/file/d/1QDCjGZJ8-FmJE3bZdIQNwnJyQKPhHZBn/view?usp=sharing).\n",
    "\n",
    "Non-compliance with the honour code constitutes a material breach of contract."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries and Read In the Data\n",
    "\n",
    "Do not modify or remove any of the code in these cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.8.0-cp39-cp39-win_amd64.whl (438.0 MB)\n",
      "Collecting flatbuffers>=1.12\n",
      "  Downloading flatbuffers-2.0-py2.py3-none-any.whl (26 kB)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (1.16.0)\n",
      "Collecting opt-einsum>=2.3.2\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (1.12.1)\n",
      "Collecting termcolor>=1.1.0\n",
      "  Downloading termcolor-1.1.0.tar.gz (3.9 kB)\n",
      "Collecting tf-estimator-nightly==2.8.0.dev2021122109\n",
      "  Downloading tf_estimator_nightly-2.8.0.dev2021122109-py2.py3-none-any.whl (462 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (3.10.0.2)\n",
      "Collecting absl-py>=0.4.0\n",
      "  Downloading absl_py-1.0.0-py3-none-any.whl (126 kB)\n",
      "Collecting tensorboard<2.9,>=2.8\n",
      "  Downloading tensorboard-2.8.0-py3-none-any.whl (5.8 MB)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (3.2.1)\n",
      "Collecting grpcio<2.0,>=1.24.3\n",
      "  Downloading grpcio-1.44.0-cp39-cp39-win_amd64.whl (3.4 MB)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (3.20.1)\n",
      "Collecting google-pasta>=0.1.1\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Collecting gast>=0.2.1\n",
      "  Downloading gast-0.5.3-py3-none-any.whl (19 kB)\n",
      "Collecting libclang>=9.0.1\n",
      "  Downloading libclang-14.0.1-py2.py3-none-win_amd64.whl (14.2 MB)\n",
      "Collecting astunparse>=1.6.0\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (1.20.3)\n",
      "Collecting keras-preprocessing>=1.1.1\n",
      "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.25.0-cp39-cp39-win_amd64.whl (1.5 MB)\n",
      "Requirement already satisfied: setuptools in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (58.0.4)\n",
      "Collecting keras<2.9,>=2.8.0rc0\n",
      "  Downloading keras-2.8.0-py2.py3-none-any.whl (1.4 MB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.37.0)\n",
      "Collecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.3.6-py3-none-any.whl (97 kB)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
      "Collecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Downloading tensorboard_data_server-0.6.1-py3-none-any.whl (2.4 kB)\n",
      "Collecting google-auth<3,>=1.6.3\n",
      "  Downloading google_auth-2.6.6-py2.py3-none-any.whl (156 kB)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.0.2)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.26.0)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Downloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "Collecting cachetools<6.0,>=2.0.0\n",
      "  Downloading cachetools-5.0.0-py3-none-any.whl (9.1 kB)\n",
      "Collecting rsa<5,>=3.1.4\n",
      "  Downloading rsa-4.8-py3-none-any.whl (39 kB)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in c:\\programdata\\anaconda3\\lib\\site-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (4.8.1)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (3.6.0)\n",
      "Collecting pyasn1<0.5.0,>=0.4.6\n",
      "  Downloading pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (3.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (1.26.7)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.2.0-py3-none-any.whl (151 kB)\n",
      "Building wheels for collected packages: termcolor\n",
      "  Building wheel for termcolor (setup.py): started\n",
      "  Building wheel for termcolor (setup.py): finished with status 'done'\n",
      "  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4847 sha256=b281f9447c2f777677a0015a4ff20df6bf9658087fcb900b540313fffecec026\n",
      "  Stored in directory: c:\\users\\z7541811\\appdata\\local\\pip\\cache\\wheels\\b6\\0d\\90\\0d1bbd99855f99cb2f6c2e5ff96f8023fad8ec367695f7d72d\n",
      "Successfully built termcolor\n",
      "Installing collected packages: pyasn1, rsa, pyasn1-modules, oauthlib, cachetools, requests-oauthlib, google-auth, tensorboard-plugin-wit, tensorboard-data-server, markdown, grpcio, google-auth-oauthlib, absl-py, tf-estimator-nightly, termcolor, tensorflow-io-gcs-filesystem, tensorboard, opt-einsum, libclang, keras-preprocessing, keras, google-pasta, gast, flatbuffers, astunparse, tensorflow\n",
      "Successfully installed absl-py-1.0.0 astunparse-1.6.3 cachetools-5.0.0 flatbuffers-2.0 gast-0.5.3 google-auth-2.6.6 google-auth-oauthlib-0.4.6 google-pasta-0.2.0 grpcio-1.44.0 keras-2.8.0 keras-preprocessing-1.1.2 libclang-14.0.1 markdown-3.3.6 oauthlib-3.2.0 opt-einsum-3.3.0 pyasn1-0.4.8 pyasn1-modules-0.2.8 requests-oauthlib-1.3.1 rsa-4.8 tensorboard-2.8.0 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 tensorflow-2.8.0 tensorflow-io-gcs-filesystem-0.25.0 termcolor-1.1.0 tf-estimator-nightly-2.8.0.dev2021122109\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_10372/1554494898.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_selection\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mf_classif\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 57\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     58\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "# Libraries for data loading, data manipulation and data visulisation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython import display\n",
    "from IPython.display import Image, IFrame\n",
    "import sklearn\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt \n",
    "import string\n",
    "import urllib\n",
    "import math\n",
    "from random import randint\n",
    "import re\n",
    "import csv\n",
    "import matplotlib.image as mpimg\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "# Libraries for NLTK\n",
    "import nltk\n",
    "from nltk import TreebankWordTokenizer, PorterStemmer, LancasterStemmer, SnowballStemmer\n",
    "from nltk.tokenize import word_tokenize, TweetTokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Libraries for data prep and classification algorithms\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier as xgb\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Libraries for Performance Metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "\n",
    "# Libraries for model optimisation\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn import feature_selection\n",
    "from sklearn.feature_selection import f_classif\n",
    "\n",
    "#Try Deep Learning\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>message</th>\n",
       "      <th>tweetid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>PolySciMajor EPA chief doesn't think carbon di...</td>\n",
       "      <td>625221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>It's not like we lack evidence of anthropogeni...</td>\n",
       "      <td>126103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>RT @RawStory: Researchers say we have three ye...</td>\n",
       "      <td>698562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>#TodayinMaker# WIRED : 2016 was a pivotal year...</td>\n",
       "      <td>573736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>RT @SoyNovioDeTodas: It's 2016, and a racist, ...</td>\n",
       "      <td>466954</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                            message  tweetid\n",
       "0          1  PolySciMajor EPA chief doesn't think carbon di...   625221\n",
       "1          1  It's not like we lack evidence of anthropogeni...   126103\n",
       "2          2  RT @RawStory: Researchers say we have three ye...   698562\n",
       "3          1  #TodayinMaker# WIRED : 2016 was a pivotal year...   573736\n",
       "4          1  RT @SoyNovioDeTodas: It's 2016, and a racist, ...   466954"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load datasets\n",
    "train  = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test_with_no_labels.csv')\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "      <th>tweetid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Europe will now be looking to China to make su...</td>\n",
       "      <td>169760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Combine this with the polling of staffers re c...</td>\n",
       "      <td>35326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The scary, unimpeachable evidence that climate...</td>\n",
       "      <td>224985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@Karoli @morgfair @OsborneInk @dailykos \\nPuti...</td>\n",
       "      <td>476263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RT @FakeWillMoore: 'Female orgasms cause globa...</td>\n",
       "      <td>872928</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             message  tweetid\n",
       "0  Europe will now be looking to China to make su...   169760\n",
       "1  Combine this with the polling of staffers re c...    35326\n",
       "2  The scary, unimpeachable evidence that climate...   224985\n",
       "3  @Karoli @morgfair @OsborneInk @dailykos \\nPuti...   476263\n",
       "4  RT @FakeWillMoore: 'Female orgasms cause globa...   872928"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'RT @thenation: Mike Pence doesnât believe in global warming or that smoking causes lung cancer. https://t.co/gvWYaauU8R'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.message[6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "Refer to this diagram to guide you while you build your model. Some of the steps will be fleshed out in this template."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Overview](process_overview_final.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic preprocessing\n",
    "\n",
    "Here is a template you may use for your initial base model. \n",
    "\n",
    "### Removing URL's\n",
    "Write a function that removes URL's from a single tweet. \n",
    "\n",
    "**Function input:**\n",
    "- A single string object (tweet) \n",
    "\n",
    "**Function output:**\n",
    "- The tweet with URL's removed as a single object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_urls(text):\n",
    "    text = re.sub(r'http[s]?://(?:[A-Za-z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9A-Fa-f][0-9A-Fa-f]))+', r'url-web', text, flags=re.MULTILINE)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert to lowercase\n",
    "\n",
    "Write a function that converts a single tweet to lowercase.\n",
    "\n",
    "**Function input:**\n",
    "- A single string object (tweet) \n",
    "\n",
    "**Function output:**\n",
    "- The tweet in lowercase as a single object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lowerd(text):\n",
    "    return text.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove Stopwords and Punctuations\n",
    "def remove_stopwords(text):\n",
    "    stops = stopwords.words('english')\n",
    "    return ' '.join([word for word in text.split() if word not in stops])\n",
    "def remove_punctuations(text):\n",
    "    for punctuation in string.punctuation:\n",
    "        text = text.replace(punctuation, '')\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenized(text):\n",
    "    tk = TweetTokenizer()\n",
    "    return tk.tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmad(words):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    return [lemmatizer.lemmatize(word) for word in words] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Check Class Balance\n",
    "Bars=train[['message','sentiment']].groupby('sentiment').count()\n",
    "Bars.sort_values('message', ascending=False).plot(kind='bar')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply all cleaning functions\n",
    "\n",
    "Simply using the pandas apply() method on the data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['message']=train['message'].apply(remove_urls).apply(lowerd).apply(remove_stopwords).apply(remove_punctuations).apply(tokenized).apply(lemmad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rt',\n",
       " 'thenation',\n",
       " 'mike',\n",
       " 'penny',\n",
       " 'doesn',\n",
       " 'â',\n",
       " 't',\n",
       " 'believe',\n",
       " 'global',\n",
       " 'warming',\n",
       " 'smoking',\n",
       " 'cause',\n",
       " 'lung',\n",
       " 'cancer',\n",
       " 'urlweb']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.message[6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorising \n",
    "\n",
    "Vectorise your cleaned data using the vectoriser you defined earlier. Don't forget to fit the vectoriser to the data you just cleaned. Store your vectorised data in `train_vec`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Z7541811\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\feature_extraction\\text.py:516: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#Feature exctraction with Term frequency inverse document frequency\n",
    "Xvector=TfidfVectorizer(preprocessor=list, tokenizer=list,\n",
    "                        ngram_range=(1,2), \n",
    "                        min_df=2,\n",
    "                        strip_accents=\"ascii\",\n",
    "                        max_features=10000,\n",
    "                        smooth_idf=False)\n",
    "\n",
    "Xvector.fit(train['message'])\n",
    "X=Xvector.transform(train['message']).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15819, 10000)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=train[\"sentiment\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    1\n",
       "2    2\n",
       "3    1\n",
       "4    1\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train_test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, shuffle=True,test_size=0.2,random_state=2023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.15321647, 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10382    0\n",
       "7937    -1\n",
       "12947    2\n",
       "7467     2\n",
       "14145    0\n",
       "        ..\n",
       "6049     1\n",
       "2743     1\n",
       "14790    1\n",
       "5657    -1\n",
       "4951    -1\n",
       "Name: sentiment, Length: 12655, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting a simple model on training data and evaluate its performance\n",
    "\n",
    "Fit a model on your cleaned data. Use `train_vec` as your features. Note that you need to convert `train_vec` to an array. \n",
    "\n",
    "You are familiar with this process, so there is less guidance here. You may also refer to train notebooks and the webinar pdf as guidance.\n",
    "\n",
    "Your basic model should be a logistic regression, however if you try different models you will also perform the following procedure.\n",
    "\n",
    "1. Split the training data into features and labels.\n",
    "2. Split the training data further into training and validation data.\n",
    "3. Fit the model on the training subset. \n",
    "4. Predict on the validation subset.\n",
    "5. Calculate the performance metrics on the validation predictions.\n",
    "6. Select a model based on validation performance (when you have more than one model).\n",
    "8. Clean the test data.\n",
    "9. Predict on the cleaned test data.\n",
    "7. Write a csv that matches `sample_submission.csv`.\n",
    "8. Submit to Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Base_Logistic_Regression\n",
    "lr_base=LogisticRegression(multi_class='ovr')\n",
    "lr_base.fit(X_train,y_train)\n",
    "lrb_pred= lr_base.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6007020546324652"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test, lrb_pred, average=\"macro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "C:\\Users\\Z7541811\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Z7541811\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Z7541811\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Z7541811\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:   58.0s finished\n"
     ]
    }
   ],
   "source": [
    "#Logistic_Regression2\n",
    "lr2=LogisticRegression(multi_class='ovr', verbose = 1, C=7)\n",
    "lr2.fit(X_train,y_train)\n",
    "lr2_pred= lr_base.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6007020546324652"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test, lr2_pred, average=\"macro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tune_Logistic_Regression using RandomGrid SearchCV\n",
    "Solver=[\"lbfgs\",\"liblinear\"]\n",
    "Cs=[int(x) for x in range(1,11,1)]\n",
    "verbosey=[0.1,1,10]\n",
    "# Create the randomgrid\n",
    "random_grid = {'solver': Solver,\n",
    "               'C': Cs,\n",
    "               'verbose': verbosey}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, error_score='raise',\n",
       "                   estimator=LogisticRegression(multi_class='ovr'), n_iter=8,\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={'C': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
       "                                        'solver': ['lbfgs', 'liblinear'],\n",
       "                                        'verbose': [0.1, 1, 10]},\n",
       "                   random_state=2023)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tlr = LogisticRegression(multi_class='ovr')\n",
    "lrt = RandomizedSearchCV(estimator = tlr,\n",
    "                         param_distributions = random_grid,\n",
    "                         n_iter =8,\n",
    "                         cv = 3,\n",
    "                         n_jobs = -1,\n",
    "                         error_score=\"raise\",\n",
    "                         random_state=2023)\n",
    "\n",
    "lrt.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6753418855900009"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lrt_pred= lrt.predict(X_test)\n",
    "f1_score(y_test, lrt_pred, average=\"macro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RidgeClassifier()"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Rclf=RidgeClassifier()\n",
    "Rclf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6712841386889433"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Rcf_pred= Rclf.predict(X_test)\n",
    "f1_score(y_test, Rcf_pred, average=\"macro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(kernel='linear')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc=SVC(kernel = 'linear')\n",
    "svc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6756354073274011"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sv_pred= svc.predict(X_test)\n",
    "f1_score(y_test, sv_pred, average=\"macro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:23:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
       "              gamma=0, gpu_id=-1, importance_type=None,\n",
       "              interaction_constraints='', learning_rate=0.300000012,\n",
       "              max_delta_step=0, max_depth=6, min_child_weight=1, missing=nan,\n",
       "              monotone_constraints='()', n_estimators=100, n_jobs=8,\n",
       "              num_parallel_tree=1, objective='multi:softprob', predictor='auto',\n",
       "              random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=None,\n",
       "              subsample=1, tree_method='exact', validate_parameters=1,\n",
       "              verbosity=None)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boost=xgb()\n",
    "boost.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5900914189445687"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xg_pred= boost.predict(X_test)\n",
    "f1_score(y_test, xg_pred, average=\"macro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=100)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KNN=KNeighborsClassifier(n_neighbors=100)\n",
    "KNN.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.46709034016235984"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_pred= KNN.predict(X_test)\n",
    "f1_score(y_test, k_pred, average=\"macro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stacking():\n",
    "    # define the base models\n",
    "    level0 = list()\n",
    "    level0.append(('knn', KNeighborsClassifier(n_neighbors=100)))\n",
    "    level0.append(('RFR', RandomForestClassifier(max_depth=100)))\n",
    "    level0.append(('xgb', xgb()))\n",
    "    # define meta learner model\n",
    "    level1 = LogisticRegression(multi_class='ovr')\n",
    "    # define the stacking ensemble.0\n",
    "    custom = StackingClassifier(estimators=level0, final_estimator=level1, cv=5)\n",
    "    return custom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:30:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:46:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:51:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[16:57:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:05:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:13:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "StackingClassifier(cv=5,\n",
       "                   estimators=[('knn', KNeighborsClassifier(n_neighbors=100)),\n",
       "                               ('RFR', RandomForestClassifier(max_depth=100)),\n",
       "                               ('xgb',\n",
       "                                XGBClassifier(base_score=None, booster=None,\n",
       "                                              colsample_bylevel=None,\n",
       "                                              colsample_bynode=None,\n",
       "                                              colsample_bytree=None,\n",
       "                                              enable_categorical=False,\n",
       "                                              gamma=None, gpu_id=None,\n",
       "                                              importance_type=None,\n",
       "                                              interaction_constraints=None,\n",
       "                                              learnin...\n",
       "                                              max_delta_step=None,\n",
       "                                              max_depth=None,\n",
       "                                              min_child_weight=None,\n",
       "                                              missing=nan,\n",
       "                                              monotone_constraints=None,\n",
       "                                              n_estimators=100, n_jobs=None,\n",
       "                                              num_parallel_tree=None,\n",
       "                                              predictor=None, random_state=None,\n",
       "                                              reg_alpha=None, reg_lambda=None,\n",
       "                                              scale_pos_weight=None,\n",
       "                                              subsample=None, tree_method=None,\n",
       "                                              validate_parameters=None,\n",
       "                                              verbosity=None))],\n",
       "                   final_estimator=LogisticRegression(multi_class='ovr'))"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacker = get_stacking()\n",
    "stacker.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6322645714295669"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stk_pred= stacker.predict(X_test)\n",
    "f1_score(y_test, stk_pred, average=\"macro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_voting():\n",
    "    # define the base models\n",
    "    level0 = list()\n",
    "    level0.append(('knn', KNeighborsClassifier(n_neighbors=100)))\n",
    "    level0.append(('RFR', RandomForestClassifier(max_depth=100)))\n",
    "    level0.append(('xgb', xgb()))\n",
    "    # define meta learner model\n",
    "    # define the stacking ensemble\n",
    "    custom2 = VotingClassifier(estimators=level0)\n",
    "    return custom2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:25:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('knn', KNeighborsClassifier(n_neighbors=100)),\n",
       "                             ('RFR', RandomForestClassifier(max_depth=100)),\n",
       "                             ('xgb',\n",
       "                              XGBClassifier(base_score=None, booster=None,\n",
       "                                            colsample_bylevel=None,\n",
       "                                            colsample_bynode=None,\n",
       "                                            colsample_bytree=None,\n",
       "                                            enable_categorical=False,\n",
       "                                            gamma=None, gpu_id=None,\n",
       "                                            importance_type=None,\n",
       "                                            interaction_constraints=None,\n",
       "                                            learning_rate=None,\n",
       "                                            max_delta_step=None, max_depth=None,\n",
       "                                            min_child_weight=None, missing=nan,\n",
       "                                            monotone_constraints=None,\n",
       "                                            n_estimators=100, n_jobs=None,\n",
       "                                            num_parallel_tree=None,\n",
       "                                            predictor=None, random_state=None,\n",
       "                                            reg_alpha=None, reg_lambda=None,\n",
       "                                            scale_pos_weight=None,\n",
       "                                            subsample=None, tree_method=None,\n",
       "                                            validate_parameters=None,\n",
       "                                            verbosity=None))])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voter = get_voting()\n",
    "voter.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5657171966371097"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vot_pred= voter.predict(X_test)\n",
    "f1_score(y_test, vot_pred, average=\"macro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 116,   31,  124,   12],\n",
       "       [  11,  196,  199,   34],\n",
       "       [   8,   60, 1501,  127],\n",
       "       [   4,    8,  143,  590]], dtype=int64)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test,Rcf_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 118,   35,  118,   12],\n",
       "       [  14,  208,  187,   31],\n",
       "       [  12,   72, 1494,  118],\n",
       "       [   3,    9,  145,  588]], dtype=int64)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test,lrt_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels=[\"1:Pro\",\"2:MorePro\",\"0:Neutral\",\"-1:Anti\"]\n",
    "pd.DataFrame(data=confusion_matrix(y_test, Rcf_pred), index=labels, columns=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TRANSFORM THE TEST DATA\n",
    "test['message']=test['message'].apply(remove_urls).apply(lowerd).apply(remove_stopwords).apply(remove_punctuations).apply(tokenized).apply(lemmad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['combine',\n",
       " 'polling',\n",
       " 'staffer',\n",
       " 'climate',\n",
       " 'change',\n",
       " 'woman',\n",
       " 'right',\n",
       " 'fascist',\n",
       " 'state',\n",
       " 'urlweb']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.message[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of                                                  message  tweetid\n",
       "0      [europe, looking, china, make, sure, alone, fi...   169760\n",
       "1      [combine, polling, staffer, climate, change, w...    35326\n",
       "2      [scary, unimpeachable, evidence, climate, chan...   224985\n",
       "3      [karoli, morgfair, osborneink, dailykos, putin...   476263\n",
       "4      [rt, fakewillmoore, female, orgasm, cause, glo...   872928\n",
       "...                                                  ...      ...\n",
       "10541  [rt, brittanybohrer, brb, writing, poem, clima...   895714\n",
       "10542  [2016, year, climate, change, came, home, hott...   875167\n",
       "10543  [rt, loopvanuatu, pacific, country, positive, ...    78329\n",
       "10544  [rt, xanria, 00018, you, â, re, hot, must, cau...   867455\n",
       "10545  [rt, chloebalaoing, climate, change, global, i...   470892\n",
       "\n",
       "[10546 rows x 2 columns]>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test1=Xvector.transform(test['message']).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "predStack=stacker.predict(X_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "predStack_submit=pd.DataFrame(predStack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of        0\n",
       "0      1\n",
       "1      1\n",
       "2      1\n",
       "3      1\n",
       "4      0\n",
       "...   ..\n",
       "10541  1\n",
       "10542  1\n",
       "10543  2\n",
       "10544  0\n",
       "10545  1\n",
       "\n",
       "[10546 rows x 1 columns]>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predStack_submit.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_submit = test[['tweetid']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweetid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>169760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>224985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>476263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>872928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10541</th>\n",
       "      <td>895714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10542</th>\n",
       "      <td>875167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10543</th>\n",
       "      <td>78329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10544</th>\n",
       "      <td>867455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10545</th>\n",
       "      <td>470892</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10546 rows Ã 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       tweetid\n",
       "0       169760\n",
       "1        35326\n",
       "2       224985\n",
       "3       476263\n",
       "4       872928\n",
       "...        ...\n",
       "10541   895714\n",
       "10542   875167\n",
       "10543    78329\n",
       "10544   867455\n",
       "10545   470892\n",
       "\n",
       "[10546 rows x 1 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids_submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweetid</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>169760</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35326</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>224985</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>476263</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>872928</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tweetid  sentiment\n",
       "0   169760          1\n",
       "1    35326          1\n",
       "2   224985          1\n",
       "3   476263          1\n",
       "4   872928          0"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit_allStack= pd.concat([ids_submit.reset_index(drop=True), predStack_submit], axis=1).rename(columns = {0:'sentiment'})\n",
    "submit_allStack.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submit your best model predictions \n",
    "\n",
    "Don't forget to submit your the predictions on the best model to Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write csv for best predictions\n",
    "submit_allStack[['tweetid','sentiment']].to_csv('StackTestsubmission.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
